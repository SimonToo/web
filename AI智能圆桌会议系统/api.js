window.API_LIBRARY = [
    {
        "id": 1,
        "platform": "硅基流动",
        "url": "https://api.siliconflow.cn/v1",
        "key": "sk-huxujfvmpyojzfbvtvrsdqtbhqvornefaucszxqgxtdhpfii",
        "model": "Qwen/Qwen2.5-72B-Instruct-128K",
        "remark": "Qwen3-8B 是通义千问系列的最新大语言模型，拥有 8.2B 参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力。\n对话 Tools 推理模型 8B 128K 通用助手 文案创作 Vibe Coding\n发布日期 2025-04-29"
    },
    {
        "id": 2,
        "platform": "硅基流动",
        "url": "https://api.siliconflow.cn/v1",
        "key": "sk-huxujfvmpyojzfbvtvrsdqtbhqvornefaucszxqgxtdhpfii",
        "model": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
        "remark": "DeepSeek-R1-0528-Qwen3-8B 是通过从 DeepSeek-R1-0528 模型蒸馏思维链到 Qwen3 8B Base 获得的模型。该模型在开源模型中达到了最先进（SOTA）的性能，在 AIME 2024 测试中超越了 Qwen3 8B 10%，并达到了 Qwen3-235B-thinking 的性能水平。该模型在数学推理、编程和通用逻辑等多个基准测试中表现出色，其架构与 Qwen3-8B 相同，但共享 DeepSeek-R1-0528 的分词器配置。\n对话 推理模型 8B 128K 通用助手 数学推理\n发布日期 2025-05-28"
    },
    {
        "id": 1769236947467,
        "platform": "硅基流动",
        "url": "https://api.siliconflow.cn/v1",
        "key": "sk-huxujfvmpyojzfbvtvrsdqtbhqvornefaucszxqgxtdhpfii",
        "model": "THUDM/GLM-4.1V-9B-Thinking",
        "remark": "GLM-Z1-9B-0414 是 GLM 系列的小型模型，仅有 90 亿参数，但保持了开源传统的同时展现出惊人的能力。尽管规模较小，该模型在数学推理和通用任务上仍表现出色，其总体性能在同等规模的开源模型中已处于领先水平。研究团队采用了与大模型相同的一系列技术进行训练，使其在资源受限的场景中能够实现效率与效果的绝佳平衡，为寻求轻量级部署的用户提供强大选择。特别是在资源受限的场景下，该模型可以很好地在效率与效果之间取得平衡，为需要轻量化部署的用户提供强有力的选择。\n对话 Tools 9B 128K 推理模型 旗舰全能 长文本处理 RAG\n发布日期 2025-04-14"
    }
];